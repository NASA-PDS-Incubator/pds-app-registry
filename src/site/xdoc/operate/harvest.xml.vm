<?xml version="1.0" encoding="UTF-8"?>

<document>
<properties>
  <title>Harvest Operation</title>
</properties>

<body>

<section name="Harvest">

<p>
<ul>
  <li><a href="#Overview">Overview</a></li>
  <li><a href="#Quick_Start">Quick Start</a></li>
  <li><a href="#InputDirs">Input Directories and Filters</a></li>
  <ul>
    <li><a href="#MultiDirs">Crawl Multiple Bundles</a></li>
    <li><a href="#BundleVersions">Filtering Bundle Versions</a></li>
    <li><a href="#ProdFilter">Filtering Products by Class</a></li>
  </ul>
  <li><a href="#Extract">Extract More Metadata</a></li>
  <ul>
    <li><a href="#FileInfo">Basic File Information</a></li>
    <li><a href="#BLOB">BLOB Storage</a></li>
    <li><a href="#FileRef">File Reference / Access URL</a></li>
    <li><a href="#IntRefs">Internal References</a></li>
    <li><a href="#XPath">Extract Metadata by XPath</a></li>
    <li><a href="#DDic">Extract Metadata by Data Dictionary Class</a></li>
  </ul>
</ul>
</p>

<subsection name="Overview">

<p>
Harvest is a command-line tool for extracting metadata from PDS4 products (labels).
It parses PDS4 files and stores extracted metadata in a "newline delimited JSON" or XML file.
The JSON file can be loaded into Elasticsearch by Registry Manager.
The XML file can be loaded into Apache Solr by Solr "post" tool or from Solr admin UI.
</p>
<p>
Harvest executable scripts for Windows (<i>harvest.bat</i>) and Linux / Mac (<i>harvest</i>) 
are located in <i>bin</i> sub-folder of the installation directory (e.g., <i>/home/pds/harvest/</i>).
</p>
<p>
To see the basic usage information (shown below) run Harvest without any parameters.
</p>
<source>
Usage: harvest &lt;options&gt;

Required parameters:
  -c &lt;file&gt;     Harvest configuration file
Optional parameters:
  -f &lt;format&gt;   Output format ('json' or 'xml'). Default is 'json'
  -o &lt;dir&gt;      Output directory. Default is /tmp/harvest/out
  -l &lt;file&gt;     Log file. Default is /tmp/harvest/harvest.log
  -v &lt;level&gt;    Logger verbosity: 0=Debug, 1=Info (default), 2=Warning, 3=Error
</source>

</subsection>
</section>

<!-- ========================================================== -->

<section name="Quick Start">
<p>
To run Harvest you need an XML configuration file. 
The configuration file has several sections which control which folders and files the Harvest tool 
will crawl and what data to extract. Very basic configuration is shown below.
<source>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;harvest&gt;
  &lt;bundles&gt;
    &lt;bundle dir="/data/LADEE/ldex_20161118" /&gt;
  &lt;/bundles&gt;
&lt;/harvest&gt;
</source>
</p>

<p>
If you save this file as <i>/tmp/ladee.cfg</i> and run Harvest
<source>
harvest -c /tmp/ladee.cfg
</source>
</p>

<p> 
all XML files in <i>/data/LADEE/ldex_20161118</i> folder and its subfolders will be processed.
By default, Harvest extracts only few metadata fields, such as lid, vid, title, and product class.
Extracted metadata is saved in <i>es-docs.json</i> file. Default output directory is <i>/tmp/harvest/out/</i>.
</p>

<p>
The JSON file has two lines per record / PDS label. The first line contains document ID, for example,
</p>
<source>
{"index":{"_id":"urn:nasa:pds:ladee_ldex::1.2"}}
</source>
<p>
The second line contains all metadata extracted from a PDS label.
In the example below we split the JSON into multiple lines to make it more readable.
</p>
<source>
{
  "lid":"urn:nasa:pds:ladee_ldex",
  "vid":"1.2",
  "lidvid":"urn:nasa:pds:ladee_ldex::1.2",
  "title":"LADEE LUNAR DUST EXPERIMENT",
  "product_class":"Product_Bundle",
  "_package_id":"9e7c65ec-cc82-4e2f-b2b7-365dc4d028e0"
}
</source>

<p>
The JSON file generated by Harvest can be loaded into Elasticsearch by Registry Manager tool
or by calling Elasticsearch bulk load API.
</p>

<subsection name="Package ID">
<p>
Each Harvest run generates unique package ID, stored in <i>_package_id</i> field.
After loading extracted metadata into Elasticsearch, all documents from a particular Harvest run can be 
deleted by this package id.
</p>
</subsection>

</section>


<!-- ====================================================================== -->

<section name="Input Directories and Filters" id="InputDirs">

<subsection name="Crawl Multiple Bundles" id="MultiDirs">
<p>
To process products from multiple bundles, specify multiple &lt;bundle&gt; entries in Harvest configuration file:
<source>
&lt;harvest&gt;
  &lt;bundles&gt;
    &lt;bundle dir="/data/geo/urn-nasa-pds-kaguya_grs_spectra" /&gt;
    &lt;bundle dir="/data/geo/urn-nasa-pds-trang2020_moon_space_weathering" /&gt;
  &lt;/bundles&gt;
&lt;/harvest&gt;
</source>
</p>
</subsection>

<subsection name="Filtering Bundle Versions" id="BundleVersions">
<p>
Use "versions" attribute of the &lt;bundle&gt; tag to list versions of bundles to process.
You can separate versions by comma, semicolon or space.
</p>

<source>
&lt;harvest&gt;
  &lt;bundles&gt;
    &lt;bundle dir="/data/OREX/orex_spice" versions="7.0;8.0" /&gt;
  &lt;/bundles&gt;
&lt;/harvest&gt;
</source>

<p>
To process all versions you can use either versions="all" or no versions attribute at all.
</p>

<source>
&lt;harvest&gt;
  &lt;bundles&gt;
    &lt;bundle dir="/data/OREX/orex_spice" versions="all" /&gt;
  &lt;/bundles&gt;
&lt;/harvest&gt;
</source>

</subsection>


<subsection name="Filtering Products by Class" id="ProdFilter">
<p>
You can include or exclude products of a particular class. For example, to only process documents, add following 
product filter in Harvest configuration file:
</p>
<source>
&lt;harvest&gt;
...
  &lt;productFilter&gt;
    &lt;include&gt;Product_Document&lt;/include&gt;
  &lt;/productFilter&gt;
&lt;/harvest&gt;
</source>

</subsection>

</section>


<!-- ===================================================== -->

<section name="Extracting More Metadata" id="Extract">

<subsection name="Label and Data File Information" id="FileInfo">

<p>
To extracts label and data file information, such as file name, mime type, size, and MD5 hash, 
include the following section in the configuration file.
<source>
&lt;fileInfo /&gt;
</source>
</p>

<p>
Now if you run Harvest, both the label file information
</p>
<source>
"ops:Label_File_Info/ops:creation_date_time":"2020-11-18T22:25:05Z",
"ops:Label_File_Info/ops:file_name":"naif0012.xml",
"ops:Label_File_Info/ops:file_ref":"/C:/tmp/d5/naif0012.xml",
"ops:Label_File_Info/ops:file_size":"3398",
"ops:Label_File_Info/ops:md5_checksum":"69ea2974a93854d90399b8b8fc3d1334"
</source>

<p>
and data file information
</p>

<source>
"ops:Data_File_Info/ops:creation_date_time":"2020-11-18T22:25:17Z",
"ops:Data_File_Info/ops:file_name":"naif0012.tls",
"ops:Data_File_Info/ops:file_ref":"/C:/tmp/d5/naif0012.tls",
"ops:Data_File_Info/ops:file_size":"5257",
"ops:Data_File_Info/ops:md5_checksum":"25a2fff30b0dedb4d76c06727b1895b1",
"ops:Data_File_Info/ops:mime_type":"text/plain",
</source>

<p>
will be extracted.
</p>

<p>
If you don't want to process data files, add the following flag in Harvest configuration file.
</p>

<source>
&lt;fileInfo processDataFiles="false" /&gt;
</source>

</subsection>

<!-- =========== -->

<subsection name="BLOB Storage" id="BLOB">

<p>
You can store whole PDS product labels as BLOBs (Binary Large OBjects). 
To enable this feature, modify <i>fileInfo</i> section in Harvest configuration file.
</p>
<source>
&lt;fileInfo storeLabels="true" /&gt;
</source>

<p>
After running Harvest, <i>es-docs.json</i> file will have <i>"ops/Label_File_Info/ops/blob"</i> field with compressed product label. 
You can expect up to 900% compression rate for some files. 
For example, many LADEE housekeeping labels are about 45KB. Compressed BLOB size is about 5KB.
For smaller files, such as collection labels, compression rate is about 350% (5.5KB file is compressed to 1.6KB).
</p>

<p>
After loading data into Elasticsearch, you can extract BLOBs by running Registry Manager tool:
<source>
registry-manager export-file -lidvid urn:nasa:pds:ladee_ldex:data_calibrated::1.2 -file /tmp/data_calibrated.xml
</source>
</p>

</subsection>


<!-- ====================================== -->

<subsection name="File Reference / Access URL" id="FileRef">
<p>
Harvest extracts absolute paths of product and label files, such as
</p>

<source>
"ops:Label_File_Info/ops:file_ref":"/tmp/d5/naif0012.xml",
"ops:Data_File_Info/ops:file_ref":"/tmp/d5/naif0012.tls",
</source>

<p>
Note that on Windows, backslashes are replaced with forward slashes and disk letter is included.
</p>

<source>
"ops:Label_File_Info/ops:file_ref":"C:/tmp/d4/bundle_orex_spice_v009.xml",
</source>


<p>
To replace a file path prefix with another value, such as a URL, add &lt;fileRef/&gt; tag in Harvest configuration file:
<source>
&lt;fileInfo&gt;
  &lt;fileRef replacePrefix="/C:/tmp/d4/" with="https://naif.jpl.nasa.gov/pub/naif/pds/pds4/orex/orex_spice/" /&gt;
&lt;/fileInfo&gt;
</source>
</p>

<p>
After running Harvest, you should get different <i>file_ref</i> value:
<source>
"ops/Label_File_Info/ops/file_ref":
    "https://naif.jpl.nasa.gov/pub/naif/pds/pds4/orex/orex_spice/bundle_orex_spice_v009.xml"
</source>
</p>

</subsection>

<!-- ====================================== -->

<subsection name="Internal References" id="IntRefs">

<p>
To extract all internal references, add the following section in Harvest configuration file.
<source>
&lt;internalRefs prefix="ref_"&gt;
  &lt;lidvid convertToLid="true" keep="true" /&gt;
&lt;/internalRefs&gt;
</source>
</p>

<p>
Example output is shown below.
<source>
"ref_lid_document":"urn:nasa:pds:ladee_uvs:document:DPSIS",
"ref_lid_instrument":"urn:nasa:pds:context:instrument:instrument.uvs__ladee",
"ref_lid_investigation":"urn:nasa:pds:context:investigation:mission.ladee",
"ref_lid_product":"urn:nasa:pds:ladee_uvs:calibration:wavelength",
"ref_lid_product":"urn:nasa:pds:ladee_uvs:raw:0016o_0000",
"ref_lid_target":"urn:nasa:pds:context:target:satellite.moon",
"ref_lidvid_product":"urn:nasa:pds:ladee_uvs:calibration:wavelength::1.0",
"ref_lidvid_product":"urn:nasa:pds:ladee_uvs:raw:0016o_0000::1.0",
</source>
</p>

<p>
The format of generated field names is as follows:
<source>
&lt;prefix&gt;&lt;lid or lidvid&gt;_&lt;reference type&gt;
</source>
</p>

<p>
Prefix is configurable. Lidvids can be converted to lids. 
If <i>keep</i> attribute is <i>true</i> as in the example above, both original lidvid and generated lid references are saved. 
If <i>keep</i> attribute is <i>false</i>, then only lid reference is saved.
</p>


</subsection>


<!-- ====================================== -->

<subsection name="Extract Metadata by XPath" id="XPath">

<p>
To extract metadata by XPath, you have to create one or more mapping files and list them 
in Harvest configuration file as shown below.
<source>
&lt;harvest&gt;
...
  &lt;xpathMaps baseDir="/home/pds/harvest/conf"&gt;
    &lt;xpathMap filePath="common.xml" /&gt;
    &lt;xpathMap rootElement="Product_Observational" filePath="observational.xml" /&gt;
  &lt;/xpathMaps&gt;
&lt;/harvest&gt;
</source>
</p>

<p>
In the example above there are two <i>xpathMap</i> entries. Each entry must have <i>filePath</i> attribute 
pointing to a mapping file. A path can be either absolute or relative to the <i>baseDir</i> attribute 
of the <i>xpathMaps</i> tag. The <i>baseDir</i> attribute is optional. The same example with absolute paths
is shown below.
<source>
  &lt;xpathMaps&gt;
    &lt;xpathMap filePath="/home/pds/harvest/conf/common.xml" /&gt;
    &lt;xpathMap rootElement="Product_Observational" filePath="/home/pds/harvest/conf/observational.xml" /&gt;
  &lt;/xpathMaps&gt;
</source>
</p>

<p>
An <i>xpathMap</i> entry can have optional <i>rootElement</i> attribute. 
Without this attribute, XPaths queries defined in a mapping file (<i>common.xml</i>),
will run against every XML document processed by Harvest.
With <i>rootElement</i> attribute, only XMLs with that root element will be processed.
</p>

<h4>Mapping Files</h4>

<p>
A mapping file has one or more entries which map an output field name to an XPath query.
For example, to extract <i>start_date_time</i> and <i>stop_date_time</i> from observational products,
you can use the following file.
</p>

<source>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;xpaths&gt;
  &lt;xpath fieldName="start_date_time"&gt;/Product_Observational/Observation_Area/Time_Coordinates/start_date_time&lt;/xpath&gt;
  &lt;xpath fieldName="stop_date_time"&gt;/Product_Observational/Observation_Area/Time_Coordinates/stop_date_time&lt;/xpath&gt;
&lt;/xpaths&gt;
</source>

<p>
You can use optional <i>dataType="date"</i> attribute to convert valid PDS dates to 
ISO-8601 "instant" format (e.g., "2013-10-24T00:49:37.457Z").
</p>

<source>
&lt;xpaths&gt;
  &lt;xpath fieldName="start_date_time" dataType="date"&gt;/Product_Observational/Observation_Area/Time_Coordinates/start_date_time&lt;/xpath&gt;
  &lt;xpath fieldName="stop_date_time" dataType="date"&gt;/Product_Observational/Observation_Area/Time_Coordinates/stop_date_time&lt;/xpath&gt;
&lt;/xpaths&gt;
</source>

<h4>XML Name Spaces</h4>
<p>
Harvest ignores namespaces when extracting metadata by XPath.
Below is a fragment of LADEE UVS product label which uses "ladee" namespace for mission area fields.
</p>

<source>
  &lt;Observation_Area&gt;
    &lt;Mission_Area&gt;
      &lt;ladee:latitude&gt;17.2367925372247&lt;/ladee:latitude&gt;
      &lt;ladee:longitude&gt;194.054477731391&lt;/ladee:longitude&gt; 
      ...
</source>

<p>
To extract latitude and longitude you can use the following XPaths without namespaces.
</p>

<source>
&lt;xpaths&gt;
  &lt;xpath fieldName="latitude"&gt;//Mission_Area/latitude&lt;/xpath&gt;
  &lt;xpath fieldName="longitude"&gt;//Mission_Area/longitude&lt;/xpath&gt;
&lt;/xpaths&gt;
</source>

</subsection>

<!-- ====================================== -->

<subsection name="Extract Metadata by Data Dictionary Class / Extract All Fields" id="DDic">

<p>
Harvest can automatically "flatten out" PDS label files and generate field names using the following naming convention:
</p>
<source>
&lt;namespace&gt;/&lt;class name&gt;/&lt;namespace&gt;/&lt;attribute name&gt;
</source>

<p>
For example
</p>
<source>
"pds/Investigation_Area/pds/name":"LADEE",
"pds/Investigation_Area/pds/type":"Mission",
"pds/Mission_Area/ladee/activity_number":"16",
"pds/Mission_Area/ladee/activity_type":"Occultation",
"pds/Mission_Area/ladee/altitude":"245.731087458064",
</source>

<p>
To extract all fields, add the following section in Harvest configuration file.
</p>
<source>
  &lt;autogenFields /&gt;
</source>

<p>
To extract a subset of fields, add <i>classFilter</i> section which can have a list of 
either include or exclude filters (but not both). The following example will extract all fields from mission area.
</p>
<source>
  &lt;autogenFields&gt;
    &lt;classFilter&gt;
      &lt;include&gt;pds.Mission_Area&lt;/include&gt;
    &lt;/classFilter&gt;
  &lt;/autogenFields&gt;
</source>

<h4>Date Fields</h4>
<p>
Harvest will try to convert all fields containing "date" string in their names to 
ISO-8601 "instant" format (e.g., "2013-10-24T00:49:37.457Z").
If a field value could not be converted to ISO-8601 format, a warning message will be printed 
and original value will be saved.
</p>

</subsection>


</section>


</body>
</document>
